# -*- coding: utf-8 -*-
"""NLP Risk Flag Production Grade Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17AED1a8I6WAKjEiVrE52kg0mmhDGk46T

##**Install & Import**
"""

!pip install spacy

import spacy
from spacy.tokens import Doc
from spacy.language import Language

"""##**Preprocessor Component**"""

@Language.component('preprocessor')

def preprocessor_component(doc: Doc):
  doc._.cleaned_text = doc.text.strip().replace('\n', ' ')
  return doc

Doc.set_extension("cleaned_text", default="")

"""##**Risk Flagger Component**"""

@Language.component('risk_flagger')

def risk_flagger_component(doc: Doc):
  risk_keywords = ['fraud' , 'hack' , 'scam' , 'unauthorized']
  doc._.has_risk = any(word in doc.text.lower() for word in risk_keywords)
  return doc

Doc.set_extension('has_risk' , default=False , force=True)

"""## **Postprocessor Component**"""

@Language.component('postprocessor')

def postprocessor_component(doc: Doc) -> Doc:
  doc._.output = {
      'entities': [(ent.text , ent.label_) for ent in doc.ents],
      'risk_flag' : doc._.has_risk,
      'cleaned': doc._.cleaned_text
  }

  return doc


Doc.set_extension('output' , default={} , force=True)

"""## **Build NLP Pipeline**"""

def build_nlp_pipeline(model: str = 'en_core_web_sm') -> Language:
  nlp = spacy.load(model)

  # add our custom components
  nlp.add_pipe('preprocessor',first=True)
  nlp.add_pipe('risk_flagger',after='ner')
  nlp.add_pipe('postprocessor',last=True)

  return nlp

"""## **Use the Pipeline**"""

nlp = build_nlp_pipeline()


texts = [
    "Apple is buying a U.K. startup for $1 billion.",
    "There was a fraud detected in the payment system."
]

for doc in nlp.pipe(texts, batch_size=2):
  print(doc.text)
  print(doc._.output['entities'])
  print(doc._.output['cleaned'])
  print(doc._.output['risk_flag'])
  print()

