# -*- coding: utf-8 -*-
"""Spacy Linguistic Annotations & NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/158zyGWL2GbYEclCN3cz_zxWRIG9hi3qc
"""

!pip install spacy

import spacy , pandas as pd

nlp = spacy.load('en_core_web_sm')

docs = nlp("""
  Hey there It's NLP Line , We Learning Spacy @
  Right now!
""")

for token in docs: print(f'{token.text}')

docs = nlp("Elon Musk founded SpaceX in 2002.")

for ent in docs.ents:
  print(ent.text , ent.label_)

import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("Apple is looking at buying U.K. startup for $1 billion.")

for token in doc:
    print(f"{token.text:12} POS: {token.pos_:8} DEP: {token.dep_:10} Lemma: {token.lemma_}")

import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("Apple is acquiring a startup in the U.K. for $1 billion.")

for ent in doc.ents:
  print(ent.text , ent.label_)

from spacy import displacy

displacy.render(doc, style='ent' , jupyter=True)

def scraping_data():
  from bs4 import BeautifulSoup
  import requests
  from spacy import displacy

  # comment stock predictions
  url = 'https://www.reddit.com/r/xyz/'

  # set the user agent headers
  headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

  # Send GET request to fetch the content of the Reddit post
  response = requests.get(url , headers=headers)

  soup = BeautifulSoup(response.content , 'html.parser')

  post_content = soup.find('div' , class_='Post')

  if post_content:

    post_text = post_content.find('div' , class_='md').text.strip()

    with open('lxy-redd-183.txt' , 'w' , encoding='utf-8') as file:
       file.write(post_text)

    nlp = spacy.load('en_core_web_sm')

    with open('lxy-redd-183.txt' , 'r' , encoding='utf-8') as file:
       content = file.read()

    doc = nlp(content)

    for ent in doc.ents: print(f'DOC TEXT: {ent.text} , DOC LABEL : {ent.label_}')

    print("Extracted Post Text:")
    print(post_text)
    print("\n-----\n")


scraping_data()

import spacy

nlp = spacy.load('en_core_web_sm')

doc = nlp()

